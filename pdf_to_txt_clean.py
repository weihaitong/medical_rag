# pdf_to_txt_clean.py
import os
import re
import pdfplumber
from pathlib import Path


def clean_text(text: str) -> str:
    """
    æ¸…ç† PDF æå–çš„æ–‡æœ¬ï¼š
    - å»é™¤é¡µçœ‰/é¡µè„šï¼ˆå¦‚æœŸåˆŠåã€é¡µç ï¼‰
    - åˆå¹¶æ–­è¡Œï¼ˆä¿ç•™æ®µè½ï¼‰
    - å»é™¤å¤šä½™ç©ºè¡Œå’Œç©ºç™½
    """
    if not text:
        return ""

    lines = text.split("\n")
    cleaned_lines = []

    for line in lines:
        line = line.strip()

        # è·³è¿‡æ˜æ˜¾æ˜¯é¡µçœ‰/é¡µè„šçš„è¡Œï¼ˆå¯æ ¹æ®å®é™…æ–‡æ¡£è°ƒæ•´è§„åˆ™ï¼‰
        if not line:
            continue
        if re.match(r"^\d+$", line):  # çº¯æ•°å­—é¡µç 
            continue
        if any(header in line for header in [
            "ä¸­å", "åŒ»å­¦", "æ‚å¿—", "æŒ‡å—", "å›½å®¶", "å«å¥å§”",
            "ç¬¬.*å·", "ç¬¬.*æœŸ", "www", "Â©", "ISSN", "CN"
        ]) and len(line) < 30:
            continue

        # åˆå¹¶æ–­è¡Œï¼šå¦‚æœè¡Œæœ«æ˜¯ä¸­æ–‡å­—ç¬¦ï¼ˆéæ ‡ç‚¹ï¼‰ï¼Œåˆ™ä¸ä¸‹ä¸€è¡Œåˆå¹¶
        if cleaned_lines and re.search(r"[\u4e00-\u9fff]$", cleaned_lines[-1]) and not re.search(r"[ã€‚ï¼ï¼Ÿï¼›]$|[\dA-Za-z]$",
                                                                                                 cleaned_lines[-1]):
            cleaned_lines[-1] += line
        else:
            cleaned_lines.append(line)

    # åˆå¹¶æ®µè½ï¼ˆä¿ç•™ç©ºè¡Œåˆ†éš”ï¼‰
    result = "\n\n".join([line for line in cleaned_lines if line.strip()])

    # è¿›ä¸€æ­¥æ¸…ç†ï¼šå¤šä¸ªæ¢è¡Œ â†’ åŒæ¢è¡Œï¼Œå¤šä½™ç©ºæ ¼
    result = re.sub(r"\n{3,}", "\n\n", result)
    result = re.sub(r" {2,}", " ", result)

    return result.strip()


def convert_pdf_to_txt(pdf_path: str, output_dir: str = "data/"):
    """
    å°†å•ä¸ª PDF è½¬ä¸ºå¹²å‡€çš„ TXT æ–‡ä»¶
    """
    pdf_path = Path(pdf_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)

    txt_filename = pdf_path.stem + ".txt"
    txt_path = output_dir / txt_filename

    try:
        with pdfplumber.open(pdf_path) as pdf:
            full_text = ""
            for page in pdf.pages:
                # æå–æ–‡æœ¬ï¼ˆä¿ç•™æ¢è¡Œï¼‰
                text = page.extract_text(
                    layout=False,  # ä¸ä¸¥æ ¼ä¿ç•™å¸ƒå±€ï¼ˆé¿å…ç©ºæ ¼è¿‡å¤šï¼‰
                    x_tolerance=1,  # å®¹å¿å¾®å°æ°´å¹³åç§»
                    y_tolerance=1
                )
                if text:
                    full_text += text + "\n\n"

        # æ¸…ç†æ–‡æœ¬
        clean = clean_text(full_text)

        # å†™å…¥ TXT
        with open(txt_path, "w", encoding="utf-8") as f:
            # å¯é€‰ï¼šåœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ æ¥æºæ³¨é‡Š
            source_comment = f"[æ¥æºï¼š{pdf_path.name}]\n\n"
            f.write(source_comment + clean)

        print(f"âœ… å·²è½¬æ¢ï¼š{pdf_path.name} â†’ {txt_path}")

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥ {pdf_path.name}: {e}")


def batch_convert_pdf_to_txt(pdf_dir: str, output_dir: str = "data/"):
    """
    æ‰¹é‡è½¬æ¢ç›®å½•ä¸‹æ‰€æœ‰ PDF
    """
    pdf_dir = Path(pdf_dir)
    for pdf_file in pdf_dir.glob("*.pdf"):
        convert_pdf_to_txt(pdf_file, output_dir)


# =============================
# ä½¿ç”¨ç¤ºä¾‹
# =============================
if __name__ == "__main__":
    # æ–¹å¼1ï¼šè½¬æ¢å•ä¸ª PDF
    # convert_pdf_to_txt("downloads/diabetes_guide_2022.pdf")

    # æ–¹å¼2ï¼šæ‰¹é‡è½¬æ¢æ•´ä¸ªç›®å½•
    batch_convert_pdf_to_txt(pdf_dir="downloads/", output_dir="data/")

    print("\nğŸ‰ æ‰€æœ‰ PDF è½¬æ¢å®Œæˆï¼è¯·æ£€æŸ¥ data/ ç›®å½•ã€‚")